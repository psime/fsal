#imports

import requests
from bs4 import BeautifulSoup
import pandas as pd
def get_sdata(team_ent):
        
    base_url = "https://salarysport.com/football/premier-league/"
    #team_ent = 'aston-villa-f.c.'
    #team_ent = 'a'
    team_name = team_ent.lower()
    rows = []

    if team_name == "a":
        # List of teams when no specific team is provided
        team_list = ['aston-villa-f.c.', 'brentford', 'brighton-&-hove-albion']
    else:
        # Single URL when a specific team is provided
        team_list = [team_ent]


    for tm in team_list:
        #print(tm)
        url = f"{base_url}{tm}/"
        #print("Constructed URL:", url)


        try:
                    #print("responseblock1")
                    # Start a session and fetch the data
                    session = requests.Session()
                    #print(session)
                    session.max_redirects = 50
                    #print("th")
                    response = session.get(url, allow_redirects=True)
                    #print("responseblock")
                    #print(response)
                    response.raise_for_status()  # Raise an error if the request was unsuccessful

                    # Parse the HTML content
                    soup = BeautifulSoup(response.content, 'html.parser')
                    table = soup.find('table')
                    
                    # Extract headers
                    headers = [header.text for header in table.find_all('th')]
                    headers.append('Team')
             

                    # Extract rows
                    #rows = []
                    for row in table.find_all('tr')[1:]:
                        cells = row.find_all('td')
                        cells = [cell.text.strip() for cell in cells]
                        cells.append(tm)
                        rows.append(cells)
              
        except requests.exceptions.RequestException as e:
                print(f"Error fetching data from {url}: {e}")
                dload='F'
    
    
    #Create a DataFrame
    #print(headers)
    #print(rows) 
    df = pd.DataFrame(rows, columns=headers)
    cols = {}
    for col in df.columns:
        cols[col] = col.lower()
    df = df.rename(columns=cols) 

    #drop extra headers
    df = df.dropna(subset=['team']) 
    dload='S'

    return df


